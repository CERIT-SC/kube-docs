# MPI Operator

Zatímco [MPI](https://www.open-mpi.org/) úlohy jsou tradiční doménou v oblasti vysokovýkonného výpočetnictví, naše platforma je schopna snadno spouštět MPI úlohy pomocí MPI Operator z [kubeflow](https://www.kubeflow.org/). [MPI Operator](https://github.com/kubeflow/mpi-operator) usnadňuje provádění distribuovaného trénování ve stylu allreduce na Kubernetes. Nasadili jsme MPI Operator na úrovni clusteru, který vám umožňuje vytvořit MPI úlohu definováním Kubernetes typu `MPIJob`, úplná dokumentace o struktuře typu je k dispozici [zde](https://github.com/kubeflow/mpi-operator/blob/master/v2/crd/kubeflow.org_mpijobs.yaml). Některé dokumentace o MPI Operator lze nalézt na [webu kubeflow](https://www.kubeflow.org/docs/components/training/mpi/#creating-an-mpi-job) nebo [v tomto blogovém příspěvku](https://medium.com/kubeflow/introduction-to-kubeflow-mpi-operator-and-industry-adoption-296d5f2e6edc).

Aby bylo možné spustit MPI úlohu, jsou zapotřebí dva kroky: připravit specifický Docker obraz a vytvořit manifest MPIJob.

## MPI Job Docker Image

MPIJob očekává specifický Docker obraz, obraz musí obsahovat openssh server a tento server musí být nakonfigurován. Také je nutné vytvořit nějakého uživatele v docker obraze. Uživatel musí však přidat následující fragment pro distribuce rodiny Debian ([stáhnout zde](/examples/ceritsc/docker/Dockerfile-mpi)):

```dockerfile
RUN apt-get update && \
    apt-get -y --no-install-recommends install openmpi-bin openssh-server openssh-client bind9-host && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

RUN mkdir -p /var/run/sshd

RUN useradd -m -u 1000 user

RUN sed -i 's/[ #]\(.*StrictHostKeyChecking \).*/ \1no/g' /etc/ssh/ssh_config && \
    echo "    UserKnownHostsFile /dev/null" >> /etc/ssh/ssh_config && \
    echo "StrictModes no" > /etc/ssh/sshd_config && \
    echo "PidFile /tmp/sshd.pid" >> /etc/ssh/sshd_config && \
    echo "HostKey ~/.ssh/id_rsa" >> /etc/ssh/sshd_config && \
    echo "Port 2222" >> /etc/ssh/sshd_config && \
    echo "ListenAddress 0.0.0.0" >> /etc/ssh/sshd_config && \
    sed -i 's/.*Port 22.*/   Port 2222/g' /etc/ssh/ssh_config

WORKDIR /data

RUN chown 1000:1000 /etc/ssh/ssh_config

CMD /usr/sbin/sshd -De
```

Samozřejmě, že musíte přidat svou aplikaci a správný základní obraz jako `tensorflow` nebo `pytorch`. Stejný obraz by měl být použit pro oba `Launcher` a `Worker` Pods.

## MPI Job Manifest

Můžete [stáhnout](/examples/ceritsc/manifests/mpijob.yaml) příklad manifestu MPI Job. Tento příklad **nefunguje** tak, jak je. Musíte specifikovat `IMAGE` a `COMMAND`. Uživatel v atributu `sshAuthMountPath` musí odpovídat uživatelskému jménu vytvořenému v docker obraze. Atribut `Worker.replicas` určuje, kolik pracovníků se má vytvořit, tj. kolik paralelních úloh bude spuštěno. Také parametr `-n "2"` pro `Launcher` musí odpovídat `Worker.replicas`. Všimněte si, že číslo `2` musí být vždy uvedeno v uvozovkách `"2"`.

## Running the MPI Job

Jakmile máte docker obraz a manifest připraveny, spustíte MPI Job pomocí:
```
kubectl create -f mpijob.yaml -n namespace
```
nahraďte `namespace` svým namespace. Úlohy *Launcher* mohou nějakou dobu selhávat, to je očekávané a normální.
